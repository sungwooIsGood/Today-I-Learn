서버의 성능을 알아볼 때 다양한 지표를 통해 최적화 시킬 수 있지만 대표적으로는 응답 시간과 처리량(TPS)을 두고 글을 작성하려 한다.

TPS: 초당 몇 개의 클라이언트 요청을 처리 즉, TPS가 많을 수록 더 많은 요청을 처리할 수 있다.

응답 시간: 클라이언트의 요청 처리 후 반환 받은 시간(대기 시간 + 처리 시간)

처리 시간(Latency Time): 서버에서 작업을 처리하여 반환까지 걸린 시간

대기 시간(Processing Time): 클라이언트와 서버간의 주고 받는대 걸리는 시간

---

## TPS를 높이려면?

### 처리 시간 줄이기

---

### 서버 늘리기

- 단순하게 서버 1대가 10 TPS면, 2대면 20 TPS

### 쓰레드 풀 + DB 커넥션 풀 늘리기

- 동시 처리할 수 있는 개수 증가 기대
    - 쓰레드 풀 5, 처리 시간 1초 → TPS 5
    - 쓰레드 풀 10, 처리 시간 1초 → TPS 10

### 서버 늘리기/쓰레드 풀 늘리기 한계

- DB에 대한 부하가 임계치를 넘어가면 처리 시간이 증가하고 먹통 증상이 발생한다. 예) DB CPU가 70%, 80% 막 이렇게 증가해버린다.
    - DB 쿼리 시간 증가 → 처리 시간 길어짐 → TPS 떨어짐

다시 돌아와서 TPS를 높이려면?

- 기본적으로 처리 시간을 줄여야 한다. 이말은 즉, 처리 시간에서 비중이 높은 대상을 찾아 줄여야한다. 크게 3가지 정도가 있다.
    - **DB 연동**
    - **API 호출**
    - **데이터  핸들링 / 계산 처리**

### DB 처리 시간 줄이기

1. 쿼리 튜닝
2. 캐시
3. 장비 업그레이드
    1. primary / Replica 읽기 전용 DB → 트래픽이 늘면 읽기용 DB를 늘리면 된다.
    2. 하드웨어 업그레이드
        1. CPU, RAM, HDD→SDD

### API 호출 처리 시간 줄이기

1. 캐시
2. 호출 제거 → 데이터를 외부 시스템에 전달해야 할 때
    1. 메시징, 비동기 연동
        1. kafka, rabbit MQ 등

### 데이터 집계/계산

- 계산해야 할 것들이 있으면 미리 계산해서 캐시나 DB에 보관하기
    - 통계류 예) 좋아요 수

### 대기 시간 줄이기

---

### 대역폭

- 대역폭이 작으면 클라이언트 개수가 증가할 때 주고 받는 속도가 급격히 느려진다.
    - 고속도로 차선이 적은데 차가 증가하면 속도가 느려지는 현상과 비슷
- 대역폭을 늘리기 위해: 물리적인 장비의 경우 장비의 네트워크 관련 장치를 업그레이드해야 하고, AWS의 가상 머신은 보통 더 높은 고사양 인스턴스를 사용하면 대역폭도 함께 증가합니다.
- 세 가지 방식 고려
    - 응답 크기 줄이기
        - 응답 압축, 이미지 파일 크기 줄이기
    - 트래픽 분리
        - 이미지, 정적 파일을 CDN을 통해 제공
    - 대역폭 늘리기
        - 비용 측면에서 CDN이 유리
